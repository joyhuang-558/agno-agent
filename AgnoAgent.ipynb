{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AgnoAgent 笔记本 — 说明与运行指南\n",
        "\n",
        "## 一、整体结构（从上到下在做什么）\n",
        "\n",
        "| 区块 | 作用 |\n",
        "|------|------|\n",
        "| **0. 安装** | 安装 agno、openai、google-genai、mcp、fastapi、sqlalchemy |\n",
        "| **1. 基础 Agent** | 用 OpenRouter + InMemoryDb 建一个只会聊天的 Agent，并跑一句 \"Hello\" |\n",
        "| **2. Agent + 工具 + 结构化输出** | 给 Agent 一个「加法」工具，并让回复变成固定格式（chat / answer / tools_used） |\n",
        "| **3. 面试 Agent（简化版）** | 单 Agent：根据「技术面试 + 数据科学家」上下文，每次只出一道面试题，输出结构化（题目、类型、期望要点） |\n",
        "| **4. 完整面试系统** | 引入：RAG 知识库、State、多个工具、Coach Agent、Team、Session Summary、Workflow |\n",
        "\n",
        "## 二、各块在做什么（逐段说明）\n",
        "\n",
        "### 块 1：安装依赖（第一个代码单元）\n",
        "- 安装运行本笔记本需要的包：`agno`、`openai`、`google-genai`、`mcp`、`fastapi`、`sqlalchemy`。\n",
        "- **运行一次即可**，环境已有的话会显示已满足。\n",
        "\n",
        "### 块 2：基础 Agent（OpenRouter + 记忆）\n",
        "- 用 **OpenRouter** 接 `gpt-4o-mini`，用 **InMemoryDb** 存对话历史。\n",
        "- 建一个叫 `BasicAgent` 的 Agent，只会按「You are a helpful AI Assistant」回复。\n",
        "- **运行后**：下一个单元里 `agent.run(\"Hello, how are you?\")` 就会得到一句问候回复。\n",
        "\n",
        "### 块 3：Agent + 工具 + 结构化输出\n",
        "- **工具**：定义一个 `add(a, b)`，Agent 可以调用来做加法。\n",
        "- **结构化输出**：用 Pydantic 定义 `Response`，包含 `chat`（文字回复）、`answer`（数值答案）、`tools_used`（用了哪些工具）。\n",
        "- 问 \"What's 10 + 2?\" 时，Agent 会调用 `add`，并把结果填进 `Response`。\n",
        "- 这里演示：**Tool + Structured Output** 两个概念。\n",
        "\n",
        "### 块 4：面试 Agent（第一阶段，单 Agent）\n",
        "- **上下文**：面试类型 = 技术面试，角色 = 数据科学家（写在 instructions 里）。\n",
        "- **结构化输出**：`InterviewTurn` = 当前题目、题目类型、期望要点。\n",
        "- 没有 RAG/State/Team，只是「每次只出一道题、输出格式固定」的面试官。\n",
        "- 运行 `interview_agent.run(\"I'm ready. Please give me the first question.\")` 会得到第一道题和期望要点。\n",
        "\n",
        "### 块 5：完整版 — RAG 知识库\n",
        "- 从本地文件 **ds notes.markdown** 按 `##` 标题拆成多个「章节」。\n",
        "- 用 **ChromaDb** 建向量库，把每个章节塞进 **Knowledge**，供后面「按主题出题」用。\n",
        "- **注意**：`DS_NOTES_PATH` 要改成你本机的 `ds notes.markdown` 路径；没有的话要自己准备该文件或改路径。\n",
        "\n",
        "### 块 6：State + 工具（面试用）\n",
        "- **State**：记录 `used_section_titles`（已用过的章节）、`round`、`session_start_time`、`interview_ended`。\n",
        "- **工具**：\n",
        "  - `get_current_time`：当前时间；\n",
        "  - `pick_topic_from_rag`：从 RAG 里选一个**还没用过**的主题，用来出题；\n",
        "  - `end_interview`：标记面试结束。\n",
        "- 这些工具在后面的 Interviewer Agent 里会被调用。\n",
        "\n",
        "### 块 7：Coach Agent + request_feedback\n",
        "- **Coach Agent**：专门做「反馈/评分」，输入题目 + 候选人答案 + RAG 参考，输出分数、覆盖要点、遗漏要点、建议。\n",
        "- **request_feedback**：一个工具，Interviewer 在候选人答完题后调用，内部会查 RAG、调 Coach，把结构化反馈转成一段文字给用户。\n",
        "\n",
        "### 块 8：Interviewer Agent + Team\n",
        "- **Interviewer Agent**：负责出题、控场，带着上面所有工具 + State + RAG，输出 `InterviewTurn`（题目、类型、期望要点，结束时可有 session_summary）。\n",
        "- **Team**：把 Interviewer 和 Coach 放在一个 Team 里；实际流程里 Coach 是通过 `request_feedback` 被 Interviewer 调用的，不是 Team 自动路由。\n",
        "\n",
        "### 块 9：Session Summary + Workflow\n",
        "- **Session Summary**：面试结束时（例如用户说「结束」），用 `generate_session_summary(agent)` 再跑一次 Agent，根据对话历史生成几句总结。\n",
        "- **Workflow**：  \n",
        "  - 先「设定上下文」→ 多轮问答（你答一题，Agent 出下一题或给反馈）→ 用户说结束 → 调用 `end_interview` → 再生成 Session Summary。\n",
        "\n",
        "### 块 10：怎么「跑」一遍\n",
        "- **单轮演示**：运行「要第一题」的单元 → 再运行「模拟候选人回答 + 请求反馈」→ 再运行「结束面试 + 生成 Session Summary」。\n",
        "- **交互式多轮**：取消注释最后的 `run_interview_workflow(interviewer_agent, max_rounds=5)`，在终端里按轮次输入你的回答，说「结束」或「end」会结束并打印总结。\n",
        "\n",
        "## 三、如何运行（推荐顺序）\n",
        "\n",
        "1. **环境**：确保已安装 Python，建议用 notebook 对应的环境（如 `agno_env`）。\n",
        "2. **API Key**：在环境变量里设置 `OPENROUTER_API_KEY`，或在项目目录下建 `.env` 文件写 `OPENROUTER_API_KEY=你的key`（运行时会用 `load_dotenv()` 加载；不要提交 `.env` 或 key 到仓库）。\n",
        "3. **从顶到底顺序执行**：  \n",
        "   - 先跑「安装」单元；  \n",
        "   - 再按顺序跑完「基础 Agent」和「Agent + 工具 + 结构化输出」；  \n",
        "   - 若要试「完整面试系统」，请先准备好 `ds notes.markdown` 并改好 `DS_NOTES_PATH`，再按顺序执行 RAG、State+工具、Coach、Interviewer、Team、Summary、Workflow 各块。\n",
        "4. **只试「简化版面试」**：只运行到「面试 Agent（第一阶段）」那一段即可，不需要 RAG/ChromaDb。\n",
        "5. **交互式面试**：在完整版都跑通后，取消注释并执行 `run_interview_workflow(interviewer_agent, max_rounds=5)`，在输入框里输入你的回答，说「结束」结束面试。\n",
        "\n",
        "## 四、依赖与路径注意\n",
        "\n",
        "- **ChromaDb**：完整版需要；若报错可取消注释 `!pip install chromadb` 并执行。\n",
        "- **OPENROUTER_API_KEY**：必须在环境变量中设置且有效；不要将 key 写在代码或提交到 public 仓库。\n",
        "- **DS_NOTES_PATH**：完整版 RAG 依赖的 Markdown 路径，需改成你本机实际路径。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtmdi_IgUnIH",
        "outputId": "216fd78b-e59e-4e59-f71d-c8af9e1f4f2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: agno in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (2.4.7)\n",
            "Requirement already satisfied: openai in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (2.16.0)\n",
            "Requirement already satisfied: google-genai in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (1.60.0)\n",
            "Requirement already satisfied: mcp in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (1.26.0)\n",
            "Requirement already satisfied: fastapi in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (0.128.0)\n",
            "Requirement already satisfied: sqlalchemy in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (2.0.46)\n",
            "Requirement already satisfied: docstring-parser in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (0.17.0)\n",
            "Requirement already satisfied: gitpython in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (3.1.46)\n",
            "Requirement already satisfied: h11>=0.16.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (0.16.0)\n",
            "Requirement already satisfied: httpx[http2] in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (0.28.1)\n",
            "Requirement already satisfied: packaging in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (26.0)\n",
            "Requirement already satisfied: pydantic-settings in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (2.12.0)\n",
            "Requirement already satisfied: pydantic in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (2.12.5)\n",
            "Requirement already satisfied: python-dotenv in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (1.2.1)\n",
            "Requirement already satisfied: python-multipart in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (0.0.22)\n",
            "Requirement already satisfied: pyyaml in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (6.0.3)\n",
            "Requirement already satisfied: rich in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (14.3.1)\n",
            "Requirement already satisfied: typer in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from agno) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from httpx[http2]->agno) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from httpx[http2]->agno) (1.0.9)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from pydantic->agno) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from pydantic->agno) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from pydantic->agno) (0.4.2)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai) (2.48.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from google-genai) (2.32.5)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: cryptography>=38.0.3 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (46.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (4.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.6.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (0.6.2)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from mcp) (0.4.3)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from mcp) (4.26.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from pyjwt[crypto]>=2.10.1->mcp) (2.10.1)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from mcp) (3.2.0)\n",
            "Requirement already satisfied: starlette>=0.27 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from mcp) (0.50.0)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from mcp) (0.40.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: greenlet>=1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from sqlalchemy) (3.3.1)\n",
            "Requirement already satisfied: cffi>=2.0.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp) (0.30.0)\n",
            "Requirement already satisfied: click>=7.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from uvicorn>=0.31.1->mcp) (8.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from gitpython->agno) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython->agno) (5.0.2)\n",
            "Requirement already satisfied: h2<5,>=3 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from httpx[http2]->agno) (4.3.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]->agno) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]->agno) (4.1.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from rich->agno) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from rich->agno) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->agno) (0.1.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from typer->agno) (1.5.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install agno openai google-genai mcp fastapi sqlalchemy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI0ZQ78LUytH"
      },
      "source": [
        "# Build Agno Agent with OpenRouter\n",
        "\n",
        "Build a basic agent, then expand the agent with other Agno modules\n",
        "\n",
        "Ask me for an OpenRouter API key\n",
        "\n",
        "- [Agno Docs: Building Agents](https://docs.agno.com/basics/agents/building-agents)\n",
        "- [Agno Docs: OpenRouter](https://docs.agno.com/integrations/models/gateways/openrouter/overview)\n",
        "- [Cookbook/Examples](https://github.com/agno-agi/agno/tree/main/cookbook)\n",
        "\n",
        "Set `OPENROUTER_API_KEY` in your environment, or in the code cells below.\n",
        "\n",
        "### Models\n",
        "[See all OpenRouter models](https://openrouter.ai/models)\n",
        "- Search by price, category, parameters allowed, etc\n",
        "- **Price**: Use Free models as able, but you might need some of the paid ones for more complex tasks.\n",
        "    - Try to use ones that cost less than $1.00 per 1M / output tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4pBh1c7yU1VX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "from dotenv import load_dotenv\n",
        "from agno.agent import Agent\n",
        "from agno.models.openrouter import OpenRouter\n",
        "from agno.db.in_memory import InMemoryDb\n",
        "\n",
        "# Load environment variables from .env file if it exists\n",
        "load_dotenv()\n",
        "\n",
        "# Use env var OPENROUTER_API_KEY only (do not put API keys in this repo)\n",
        "if not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
        "    raise ValueError(\"Set OPENROUTER_API_KEY in your environment (e.g. export OPENROUTER_API_KEY=your_key) or in .env file. Do not commit keys.\")\n",
        "DB = InMemoryDb()\n",
        "SESSION_ID = 'session001'\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"BasicAgent\",\n",
        "    model=OpenRouter(\n",
        "        id='openai/gpt-4o-mini',\n",
        "        api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        "    ),\n",
        "    instructions=dedent(\n",
        "        \"\"\"\n",
        "        You are a helpful AI Assistant\n",
        "        \"\"\"\n",
        "    ),\n",
        "    db=DB,\n",
        "    session_id=SESSION_ID,\n",
        "    add_history_to_context=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K74XZIhVHXJ",
        "outputId": "01888e93-1c5a-4124-becf-cb6df9efa004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "response = agent.run(\"Hello, how are you?\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTZO3ow2Xesa"
      },
      "source": [
        "## Tasks\n",
        "Review all the modules of Agno SDK and build an over-engineered Agent that demonstrates key concepts and features\n",
        "\n",
        "1. [Agno Context Engineering](https://docs.agno.com/context/engineering/overview)\n",
        "\n",
        "2. [Structured Outputs with Pydantic](https://docs.agno.com/basics/input-output/overview#structured-output)\n",
        "\n",
        "2. [State Management / Agentic State](https://docs.agno.com/context/state/overview)\n",
        "\n",
        "3. [Knowledge / Agentic RAG](https://docs.agno.com/context/knowledge/overview)\n",
        "\n",
        "4. [Session Summary Agent](https://docs.agno.com/context/knowledge/overview)\n",
        "\n",
        "5. [Tools and Toolkits](https://docs.agno.com/integrations/toolkits/overview)\n",
        "\n",
        "6. [Reasoning](https://docs.agno.com/features/reasoning/overview)\n",
        "\n",
        "7. [Build a second agent and use as a `Team`](https://docs.agno.com/basics/teams/overview)\n",
        "\n",
        "8. [Build `Steps` and use in a `Workflow`](https://docs.agno.com/basics/workflows/building-workflows)\n",
        "\n",
        "> Does not need to especially sophisticated, and does not need to be an especially useful agent, just work to get the different elements integrated\n",
        "\n",
        "For example, add a basic tool and structured outputs to your agent:\n",
        "\n",
        "### Agent with Tool and Structured Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlEg3o6SXHHf",
        "outputId": "7189560e-1cc1-411a-88d4-2997ac040827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'chat': 'The sum of 10 and 2 is 12.', 'answer': 12, 'tools_used': ['functions.add']}\n",
            "\n",
            "Access individual fields from response:\n",
            "<class 'str'>: The sum of 10 and 2 is 12.\n",
            "<class 'int'>: 12\n",
            "<class 'list'>: ['functions.add']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "from dotenv import load_dotenv\n",
        "from agno.agent import Agent\n",
        "from agno.models.openrouter import OpenRouter\n",
        "from agno.db.in_memory import InMemoryDb\n",
        "from agno.tools import tool\n",
        "from pydantic import BaseModel, Field\n",
        "from typing_extensions import Optional, List\n",
        "\n",
        "# Load environment variables from .env file if it exists\n",
        "load_dotenv()\n",
        "\n",
        "# OPENROUTER_API_KEY must be set in environment (do not commit keys)\n",
        "if not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
        "    raise ValueError(\"Set OPENROUTER_API_KEY in your environment or .env file. Do not commit keys.\")\n",
        "DB = InMemoryDb()\n",
        "SESSION_ID = 'session001'\n",
        "\n",
        "# Create simple arithmetic tool\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\" A tool that adds integers together \"\"\"\n",
        "    return a + b\n",
        "\n",
        "# Create structured output schema with Typed data\n",
        "class Response(BaseModel):\n",
        "    \"\"\"\n",
        "    A response to a user input that includes:\n",
        "    - a normal LLM chat response\n",
        "    - a numerical answer if the user input required math tools\n",
        "    - a list of tools used (names of tools)\n",
        "    \"\"\"\n",
        "    chat: str = Field(..., description=\"The chat response to the user input\")\n",
        "    answer: Optional[int] = Field(\n",
        "        None,\n",
        "        description=\"Numerical answer to the user input if it required math tools\"\n",
        "    )\n",
        "    tools_used: List[str]\n",
        "\n",
        "# Create agent\n",
        "agent = Agent(\n",
        "    name=\"BasicAgent\",\n",
        "    model=OpenRouter(\n",
        "        id='openai/gpt-4o-mini',\n",
        "        api_key=os.environ.get('OPENROUTER_API_KEY'),\n",
        "    ),\n",
        "    instructions=dedent(\n",
        "        \"\"\"\n",
        "        You are a helpful AI Assistant. You can add two numbers together\n",
        "        using a tool, which is more accurate than LLM native arithmetic.\n",
        "        \"\"\"\n",
        "    ),\n",
        "    tools=[add],\n",
        "    db=DB,\n",
        "    session_id=SESSION_ID,\n",
        "    add_history_to_context=True,\n",
        "    output_schema=Response,\n",
        "    use_json_mode=True,  # Helps with some endpoint/model compatibility issues\n",
        "    retries=3\n",
        ")\n",
        "\n",
        "# We'll skip the pretty print response and get the data as a dict/json\n",
        "run = agent.run(\"Hey! What's 10 + 2?\")  # to display output\n",
        "print(run.content.model_dump())\n",
        "\n",
        "# Now we can access response items programatically, enabling all sorts of follow on operations\n",
        "print(\"\\nAccess individual fields from response:\")\n",
        "print(f\"{type(run.content.chat)}: {run.content.chat}\")\n",
        "print(f\"{type(run.content.answer)}: {run.content.answer}\")\n",
        "print(f\"{type(run.content.tools_used)}: {run.content.tools_used}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    def run(\n",
            "        self,\n",
            "        input: Union[str, List, Dict, Message, BaseModel, List[Message]],\n",
            "        *,\n",
            "        stream: Optional[bool] = None,\n",
            "        stream_events: Optional[bool] = None,\n",
            "        user_id: Optional[str] = None,\n",
            "        session_id: Optional[str] = None,\n",
            "        session_state: Optional[Dict[str, Any]] = None,\n",
            "        run_context: Optional[RunContext] = None,\n",
            "        run_id: Optional[str] = None,\n",
            "        audio: Optional[Sequence[Audio]] = None,\n",
            "        images: Optional[Sequence[Image]] = None,\n",
            "        videos: Optional[Sequence[Video]] = None,\n",
            "        files: Optional[Sequence[File]] = None,\n",
            "        knowledge_filters: Optional[Union[Dict[str, Any], List[FilterExpr]]] = None,\n",
            "        add_history_to_context: Optional[bool] = None,\n",
            "        add_dependencies_to_context: Optional[bool] = None,\n",
            "        add_session_state_to_context: Optional[bool] = None,\n",
            "        dependencies: Optional[Dict[str, Any]] = None,\n",
            "        metadata: Optional[Dict[str, Any]] = None,\n",
            "        output_schema: Optional[Union[Type[BaseModel], Dict[str, Any]]] = None,\n",
            "        yield_run_output: Optional[bool] = None,\n",
            "        debug_mode: Optional[bool] = None,\n",
            "        **kwargs: Any,\n",
            "    ) -> Union[RunOutput, Iterator[Union[RunOutputEvent, RunOutput]]]:\n",
            "        \"\"\"Run the Agent and return the response.\"\"\"\n",
            "        if self._has_async_db():\n",
            "            raise RuntimeError(\n",
            "                \"`run` method is not supported with an async database. Please use `arun` method instead.\"\n",
            "            )\n",
            "\n",
            "        # Initialize session early for error handling\n",
            "        session_id, user_id = self._initialize_session(session_id=session_id, user_id=user_id)\n",
            "        # Set the id for the run\n",
            "        run_id = run_id or str(uuid4())\n",
            "        register_run(run_id)\n",
            "\n",
            "        if (add_history_to_context or self.add_history_to_context) and not self.db and not self.team_id:\n",
            "            log_warning(\n",
            "                \"add_history_to_context is True, but no database has been assigned to the agent. History will not be added to the context.\"\n",
            "            )\n",
            "\n",
            "        background_tasks = kwargs.pop(\"background_tasks\", None)\n",
            "        if background_tasks is not None:\n",
            "            from fastapi import BackgroundTasks\n",
            "\n",
            "            background_tasks: BackgroundTasks = background_tasks  # type: ignore\n",
            "\n",
            "        # Validate input against input_schema if provided\n",
            "        validated_input = validate_input(input, self.input_schema)\n",
            "\n",
            "        # Normalise hook & guardails\n",
            "        if not self._hooks_normalised:\n",
            "            if self.pre_hooks:\n",
            "                self.pre_hooks = normalize_pre_hooks(self.pre_hooks)  # type: ignore\n",
            "            if self.post_hooks:\n",
            "                self.post_hooks = normalize_post_hooks(self.post_hooks)  # type: ignore\n",
            "            self._hooks_normalised = True\n",
            "\n",
            "        session_id, user_id = self._initialize_session(session_id=session_id, user_id=user_id)\n",
            "\n",
            "        # Initialize the Agent\n",
            "        self.initialize_agent(debug_mode=debug_mode)\n",
            "\n",
            "        image_artifacts, video_artifacts, audio_artifacts, file_artifacts = validate_media_object_id(\n",
            "            images=images, videos=videos, audios=audio, files=files\n",
            "        )\n",
            "\n",
            "        # Create RunInput to capture the original user input\n",
            "        run_input = RunInput(\n",
            "            input_content=validated_input,\n",
            "            images=image_artifacts,\n",
            "            videos=video_artifacts,\n",
            "            audios=audio_artifacts,\n",
            "            files=file_artifacts,\n",
            "        )\n",
            "\n",
            "        # Read existing session from database\n",
            "        agent_session = self._read_or_create_session(session_id=session_id, user_id=user_id)\n",
            "        self._update_metadata(session=agent_session)\n",
            "\n",
            "        # Initialize session state. Get it from DB if relevant.\n",
            "        session_state = session_state if session_state is not None else {}\n",
            "        session_state = self._load_session_state(session=agent_session, session_state=session_state)\n",
            "\n",
            "        # Determine runtime dependencies\n",
            "        dependencies = dependencies if dependencies is not None else self.dependencies\n",
            "\n",
            "        # Resolve output_schema parameter takes precedence, then fall back to self.output_schema\n",
            "        if output_schema is None:\n",
            "            output_schema = self.output_schema\n",
            "\n",
            "        # Initialize run context\n",
            "        run_context = run_context or RunContext(\n",
            "            run_id=run_id,\n",
            "            session_id=session_id,\n",
            "            user_id=user_id,\n",
            "            session_state=session_state,\n",
            "            dependencies=dependencies,\n",
            "            output_schema=output_schema,\n",
            "        )\n",
            "        # output_schema parameter takes priority, even if run_context was provided\n",
            "        run_context.output_schema = output_schema\n",
            "\n",
            "        # Resolve dependencies\n",
            "        if run_context.dependencies is not None:\n",
            "            self._resolve_run_dependencies(run_context=run_context)\n",
            "\n",
            "        add_dependencies = (\n",
            "            add_dependencies_to_context if add_dependencies_to_context is not None else self.add_dependencies_to_context\n",
            "        )\n",
            "        add_session_state = (\n",
            "            add_session_state_to_context\n",
            "            if add_session_state_to_context is not None\n",
            "            else self.add_session_state_to_context\n",
            "        )\n",
            "        add_history = add_history_to_context if add_history_to_context is not None else self.add_history_to_context\n",
            "\n",
            "        # When filters are passed manually\n",
            "        if self.knowledge_filters or knowledge_filters:\n",
            "            run_context.knowledge_filters = self._get_effective_filters(knowledge_filters)\n",
            "\n",
            "        # Use stream override value when necessary\n",
            "        if stream is None:\n",
            "            stream = False if self.stream is None else self.stream\n",
            "\n",
            "        # Can't stream events if streaming is disabled\n",
            "        if stream is False:\n",
            "            stream_events = False\n",
            "\n",
            "        if stream_events is None:\n",
            "            stream_events = False if self.stream_events is None else self.stream_events\n",
            "\n",
            "        # Prepare arguments for the model\n",
            "        response_format = self._get_response_format(run_context=run_context) if self.parser_model is None else None\n",
            "        self.model = cast(Model, self.model)\n",
            "\n",
            "        # Merge agent metadata with run metadata\n",
            "        if self.metadata is not None and metadata is not None:\n",
            "            merge_dictionaries(metadata, self.metadata)\n",
            "\n",
            "        # Create a new run_response for this attempt\n",
            "        run_response = RunOutput(\n",
            "            run_id=run_id,\n",
            "            session_id=session_id,\n",
            "            agent_id=self.id,\n",
            "            user_id=user_id,\n",
            "            agent_name=self.name,\n",
            "            metadata=run_context.metadata,\n",
            "            session_state=run_context.session_state,\n",
            "            input=run_input,\n",
            "        )\n",
            "\n",
            "        run_response.model = self.model.id if self.model is not None else None\n",
            "        run_response.model_provider = self.model.provider if self.model is not None else None\n",
            "\n",
            "        # Start the run metrics timer, to calculate the run duration\n",
            "        run_response.metrics = Metrics()\n",
            "        run_response.metrics.start_timer()\n",
            "\n",
            "        if stream:\n",
            "            response_iterator = self._run_stream(\n",
            "                run_response=run_response,\n",
            "                run_context=run_context,\n",
            "                session=agent_session,\n",
            "                user_id=user_id,\n",
            "                add_history_to_context=add_history,\n",
            "                add_dependencies_to_context=add_dependencies,\n",
            "                add_session_state_to_context=add_session_state,\n",
            "                response_format=response_format,\n",
            "                stream_events=stream_events,\n",
            "                yield_run_output=yield_run_output,\n",
            "                debug_mode=debug_mode,\n",
            "                background_tasks=background_tasks,\n",
            "                **kwargs,\n",
            "            )\n",
            "            return response_iterator\n",
            "        else:\n",
            "            response = self._run(\n",
            "                run_response=run_response,\n",
            "                run_context=run_context,\n",
            "                session=agent_session,\n",
            "                user_id=user_id,\n",
            "                add_history_to_context=add_history,\n",
            "                add_dependencies_to_context=add_dependencies,\n",
            "                add_session_state_to_context=add_session_state,\n",
            "                response_format=response_format,\n",
            "                debug_mode=debug_mode,\n",
            "                background_tasks=background_tasks,\n",
            "                **kwargs,\n",
            "            )\n",
            "            return response\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from agno.agent import Agent\n",
        "import inspect\n",
        "\n",
        "print(inspect.getsource(Agent.run))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interview Agent (Phase 1: Single Agent + Structured Output + Context)\n",
        "\n",
        "Mock interview coach: one agent asks questions based on **context** (interview type, role) and returns **structured output** (current question + type + expected key points). No RAG/State/Team yet—just get the conversation working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw output (dict): {'current_question': 'Can you explain the difference between Type I and Type II errors in hypothesis testing?', 'question_type': 'technical', 'expected_key_points': ['Type I error occurs when the null hypothesis is rejected when it is actually true (false positive).', 'Type II error occurs when the null hypothesis is not rejected when it is actually false (false negative).', 'The significance level (alpha) is associated with Type I error probability.', 'The power of a test is related to Type II error probability (1 - beta).', 'Importance of balancing both types of errors based on the context of the hypothesis test.']}\n",
            "\n",
            "--- Formatted ---\n",
            "Question: Can you explain the difference between Type I and Type II errors in hypothesis testing?\n",
            "Type: technical\n",
            "Expected key points: ['Type I error occurs when the null hypothesis is rejected when it is actually true (false positive).', 'Type II error occurs when the null hypothesis is not rejected when it is actually false (false negative).', 'The significance level (alpha) is associated with Type I error probability.', 'The power of a test is related to Type II error probability (1 - beta).', 'Importance of balancing both types of errors based on the context of the hypothesis test.']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "from dotenv import load_dotenv\n",
        "from agno.agent import Agent\n",
        "from agno.models.openrouter import OpenRouter\n",
        "from agno.db.in_memory import InMemoryDb\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "# Load environment variables from .env file if it exists\n",
        "load_dotenv()\n",
        "\n",
        "# OPENROUTER_API_KEY must be set in environment\n",
        "if not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
        "    raise ValueError(\"Set OPENROUTER_API_KEY in your environment or .env file. Do not commit keys.\")\n",
        "DB = InMemoryDb()\n",
        "SESSION_ID = \"interview_session_001\"\n",
        "\n",
        "# --- Context (simple context engineering) ---\n",
        "INTERVIEW_TYPE = \"technical\"\n",
        "ROLE = \"Data Scientist\"\n",
        "\n",
        "# --- Structured output: one interview turn = question + type + expected key points ---\n",
        "class InterviewTurn(BaseModel):\n",
        "    \"\"\"One interviewer turn: the question to ask and what to look for in the answer.\"\"\"\n",
        "    current_question: str = Field(..., description=\"The interview question to ask the candidate\")\n",
        "    question_type: str = Field(..., description=\"e.g. technical, behavioral, system_design\")\n",
        "    expected_key_points: List[str] = Field(..., description=\"Key points or themes to look for in a good answer\")\n",
        "\n",
        "# --- Interview Agent: single agent, structured output, context in instructions ---\n",
        "interview_agent = Agent(\n",
        "    name=\"InterviewAgent\",\n",
        "    model=OpenRouter(\n",
        "        id=\"openai/gpt-4o-mini\",\n",
        "        api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        "    ),\n",
        "    instructions=dedent(f\"\"\"\n",
        "        You are a professional interviewer conducting a mock data science interview.\n",
        "        Interview type: {INTERVIEW_TYPE}.\n",
        "        Role: {ROLE}.\n",
        "        Focus on data science topics: statistics, ML, Python/pandas, SQL, A/B testing, metrics, etc.\n",
        "        Ask exactly ONE question per turn. Be concise and professional.\n",
        "        Output your question and the expected key points in the required structured format.\n",
        "        \"\"\"),\n",
        "    db=DB,\n",
        "    session_id=SESSION_ID,\n",
        "    add_history_to_context=True,\n",
        "    output_schema=InterviewTurn,\n",
        "    use_json_mode=True,\n",
        "    retries=3,\n",
        ")\n",
        "\n",
        "# --- Run: ask for the first question ---\n",
        "run = interview_agent.run(\"I'm ready. Please give me the first question.\")\n",
        "print(\"Raw output (dict):\", run.content.model_dump())\n",
        "print(\"\\n--- Formatted ---\")\n",
        "print(f\"Question: {run.content.current_question}\")\n",
        "print(f\"Type: {run.content.question_type}\")\n",
        "print(f\"Expected key points: {run.content.expected_key_points}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Interview Agent (Full): State + RAG + Tools + Team + Session Summary + Workflow\n",
        "\n",
        "- **State**: Track `used_section_titles`, `round`, `session_start_time`, `interview_ended`\n",
        "- **RAG**: DS notes markdown chunked by `##`, used for question generation and feedback reference\n",
        "- **Tools**: `get_current_time`, `pick_topic_from_rag`, `end_interview`, `request_feedback` (calls Coach)\n",
        "- **Team**: Interviewer (出题/控场) + Coach (反馈/评分)\n",
        "- **Session Summary**: Triggered on \"end interview\", included in structured output or displayed separately\n",
        "- **Workflow**: Set context → multi-round Q&A (team) → summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.4.1-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.4.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from chromadb) (2.12.5)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.3-cp311-cp311-macosx_10_9_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
            "Collecting numpy>=1.22.5 (from chromadb)\n",
            "  Downloading numpy-2.4.1-cp311-cp311-macosx_14_0_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.2-cp311-cp311-macosx_13_0_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.22.2-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading pypika-0.50.0-py2.py3-none-any.whl.metadata (51 kB)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting importlib-resources (from chromadb)\n",
            "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb)\n",
            "  Downloading grpcio-1.76.0-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from chromadb) (0.21.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-35.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from chromadb) (6.0.3)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (14 kB)\n",
            "Collecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.11.6-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from chromadb) (14.3.1)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from chromadb) (4.26.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n",
            "Requirement already satisfied: six>=1.5 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2026.1.4)\n",
            "Requirement already satisfied: packaging>=24.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (26.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: anyio in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-6.33.4-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
            "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting huggingface-hub<2.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
            "  Downloading huggingface_hub-1.3.5-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting filelock (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
            "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
            "  Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
            "  Using cached hf_xet-1.2.0-cp37-abi3-macosx_10_12_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: shellingham in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.5.4)\n",
            "Collecting typer-slim (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
            "  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.7.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.22.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.1-cp311-cp311-macosx_10_12_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /Users/joy/opt/anaconda3/envs/agno_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb)\n",
            "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading chromadb-1.4.1-cp39-abi3-macosx_10_12_x86_64.whl (20.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading bcrypt-5.0.0-cp39-abi3-macosx_10_12_universal2.whl (495 kB)\n",
            "Downloading build-1.4.0-py3-none-any.whl (24 kB)\n",
            "Downloading grpcio-1.76.0-cp311-cp311-macosx_11_0_universal2.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-35.0.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading mmh3-5.2.0-cp311-cp311-macosx_10_9_x86_64.whl (40 kB)\n",
            "Downloading numpy-2.4.1-cp311-cp311-macosx_14_0_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp311-cp311-macosx_13_0_x86_64.whl (19.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
            "Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
            "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
            "Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
            "Downloading protobuf-6.33.4-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
            "Downloading orjson-3.11.6-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (250 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading pybase64-1.4.3-cp311-cp311-macosx_10_9_x86_64.whl (38 kB)\n",
            "Downloading pypika-0.50.0-py2.py3-none-any.whl (60 kB)\n",
            "Downloading tokenizers-0.22.2-cp39-abi3-macosx_10_12_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-1.3.5-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached hf_xet-1.2.0-cp37-abi3-macosx_10_12_x86_64.whl (2.9 MB)\n",
            "Downloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
            "Downloading httptools-0.7.1-cp311-cp311-macosx_10_9_universal2.whl (206 kB)\n",
            "Downloading uvloop-0.22.1-cp311-cp311-macosx_10_9_x86_64.whl (748 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m748.7/748.7 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp311-cp311-macosx_10_12_x86_64.whl (406 kB)\n",
            "Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
            "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
            "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
            "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
            "Installing collected packages: pypika, mpmath, flatbuffers, durationpy, zipp, websocket-client, uvloop, typer-slim, sympy, pyproject_hooks, pybase64, protobuf, overrides, orjson, oauthlib, numpy, mmh3, importlib-resources, humanfriendly, httptools, hf-xet, grpcio, fsspec, filelock, bcrypt, backoff, watchfiles, requests-oauthlib, posthog, opentelemetry-proto, importlib-metadata, googleapis-common-protos, coloredlogs, build, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, kubernetes, huggingface-hub, tokenizers, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44/44\u001b[0m [chromadb]chromadb]tokenizers]-hub]n-protos]\n",
            "\u001b[1A\u001b[2KSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.4.0 chromadb-1.4.1 coloredlogs-15.0.1 durationpy-0.10 filelock-3.20.3 flatbuffers-25.12.19 fsspec-2026.1.0 googleapis-common-protos-1.72.0 grpcio-1.76.0 hf-xet-1.2.0 httptools-0.7.1 huggingface-hub-1.3.5 humanfriendly-10.0 importlib-metadata-8.7.1 importlib-resources-6.5.2 kubernetes-35.0.0 mmh3-5.2.0 mpmath-1.3.0 numpy-2.4.1 oauthlib-3.3.1 onnxruntime-1.23.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 orjson-3.11.6 overrides-7.7.0 posthog-5.4.0 protobuf-6.33.4 pybase64-1.4.3 pypika-0.50.0 pyproject_hooks-1.2.0 requests-oauthlib-2.0.0 sympy-1.14.0 tokenizers-0.22.2 typer-slim-0.21.1 uvloop-0.22.1 watchfiles-1.1.1 websocket-client-1.9.0 zipp-3.23.0\n"
          ]
        }
      ],
      "source": [
        "# Optional: install chromadb for vector store (run this cell if you get ModuleNotFoundError: chromadb)\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsed 79 sections (##). First 3 titles: ['ML训练中错误来源', '防止过拟合手段', '数据标准化']\n"
          ]
        }
      ],
      "source": [
        "# --- 1. RAG: Build knowledge base from DS notes (chunk by ## sections) ---\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file if it exists\n",
        "load_dotenv()\n",
        "\n",
        "# Check if OPENROUTER_API_KEY is set\n",
        "if not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
        "    raise ValueError(\"Set OPENROUTER_API_KEY in your environment or .env file. Do not commit keys.\")\n",
        "\n",
        "# ChromaDb default embedder may need OPENAI_API_KEY; or pass a custom embedder to ChromaDb\n",
        "DS_NOTES_PATH = \"/Users/joy/Desktop/ds notes.markdown\"\n",
        "\n",
        "def parse_markdown_by_h2(path: str) -> list[tuple[str, str]]:\n",
        "    \"\"\"Parse markdown file into (section_title, content) pairs by ## headers.\"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "    # Split by ## but keep the header line with the content\n",
        "    pattern = re.compile(r\"^##\\s+(.+)$\", re.MULTILINE)\n",
        "    parts = pattern.split(text)\n",
        "    # parts[0] is content before first ##; then [title1, content1, title2, content2, ...]\n",
        "    sections = []\n",
        "    if len(parts) <= 1:\n",
        "        if text.strip():\n",
        "            sections.append((\"general\", text))\n",
        "        return sections\n",
        "    # Skip leading content without ## (e.g. first line or intro)\n",
        "    i = 1\n",
        "    while i + 1 < len(parts):\n",
        "        title, content = parts[i].strip(), (parts[i + 1] or \"\").strip()\n",
        "        if title or content:\n",
        "            sections.append((title or \"section\", content or \"(no content)\"))\n",
        "        i += 2\n",
        "    return sections\n",
        "\n",
        "sections = parse_markdown_by_h2(DS_NOTES_PATH)\n",
        "print(f\"Parsed {len(sections)} sections (##). First 3 titles: {[t for t, _ in sections[:3]]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted=74, skipped=5, failed=0\n"
          ]
        }
      ],
      "source": [
        "from agno.knowledge import Knowledge\n",
        "from agno.knowledge.embedder.openai import OpenAIEmbedder\n",
        "from agno.vectordb.chroma import ChromaDb\n",
        "from chromadb import PersistentClient\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "CHROMA_PATH = \"./tmp_interview_chroma\"\n",
        "COLLECTION = \"ds_notes_emb1536\"\n",
        "\n",
        "Path(CHROMA_PATH).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "EMBED_MODEL = \"text-embedding-3-small\"  # 1536 dim\n",
        "embedder = OpenAIEmbedder(\n",
        "    id=EMBED_MODEL,\n",
        "    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        ")\n",
        "\n",
        "# 1️⃣ 先彻底删旧库\n",
        "client = PersistentClient(path=CHROMA_PATH)\n",
        "if COLLECTION in [c.name for c in client.list_collections()]:\n",
        "    client.delete_collection(COLLECTION)\n",
        "\n",
        "# 2️⃣ 创建新 collection（维度在这里被“锁定”）\n",
        "coll = client.get_or_create_collection(\n",
        "    COLLECTION,\n",
        "    metadata={\"hnsw:space\": \"cosine\"},\n",
        ")\n",
        "\n",
        "# 3️⃣ 插入\n",
        "inserted = skipped = failed = 0\n",
        "for i, (title, content) in enumerate(sections):\n",
        "    if not isinstance(content, str):\n",
        "        skipped += 1\n",
        "        continue\n",
        "    if len(content.strip()) < 30 or content.strip().startswith(\"![\"):\n",
        "        skipped += 1\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        emb = embedder.get_embedding(content)\n",
        "        if not emb:\n",
        "            failed += 1\n",
        "            continue\n",
        "\n",
        "        coll.upsert(\n",
        "            ids=[f\"ds_sec_{i}\"],\n",
        "            embeddings=[emb],\n",
        "            documents=[content],\n",
        "            metadatas=[{\"section_title\": title}],\n",
        "        )\n",
        "        inserted += 1\n",
        "    except Exception as e:\n",
        "        failed += 1\n",
        "        print(\"Insert fail:\", e)\n",
        "\n",
        "print(f\"Inserted={inserted}, skipped={skipped}, failed={failed}\")\n",
        "\n",
        "# 4️⃣ 最后再把 Knowledge / ChromaDb 指向这个 collection\n",
        "vector_db = ChromaDb(\n",
        "    collection=COLLECTION,\n",
        "    path=CHROMA_PATH,\n",
        "    embedder=embedder,\n",
        "    persistent_client=True,\n",
        ")\n",
        "\n",
        "knowledge = Knowledge(\n",
        "    name=COLLECTION,\n",
        "    vector_db=vector_db,\n",
        "    max_results=5,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['### Early stop\\n\\n用于防止模型**过拟合（一种正则化手段）**。它通过监控模型在validation set上的表现，决定是否需要提前结束训练。\\n\\n具体流程：设定一个最大迭代次数，记录每次iteration之后的loss，如果loss到某个epoch之后开始出现上升，则继续训练以观察是否是短期波动，如果验证损失在接下来的10个epoch中，都没有比best—loss低，则Early Stopping\\n\\n### Drop out\\n\\n 防止模型**过拟合（一种正则化手段）。**\\n\\n- 在训练过程中，每一层的每个神经元都有drop rate的概率被丢弃（output会直接被设为零），所以这个神经元对该 batch 的训练过程没有贡献。\\n- 每次前向传播，都会随机重新丢弃一些神经元，这就是**独立采样Independent Sampling。**导致每个 batch 中的**模型结构都不同**。Dropout 具有类似**ensemble**的效果，从而增强了模型的泛化能力。\\n- 在反向传播时，模型只会计算那些**未被丢弃的神经元**的梯度，并根据这些梯度更新权重。\\n- **测试阶段**不同于训练阶段，因为在测试时模型要提供稳定的output，因此所有神经元都会被激活。为的是总输出保持与训练阶段一致 To maintain consistency between training and testing outputs，将所有神经元的输出乘以 **(1−dropout rate)。**\\n\\n好处：防止过拟合，降低对特定神经元的依赖（增强鲁棒性）', '- **person**\\n\\n![img](https://my.feishu.cn/space/api/box/stream/download/asynccode/?code=NjkwMTg5YzNiYWVjMWUwNTgzMmJhOTc1ODIyMTAxZTJfZ3JOOGtucVJkTzZ5eVhUNzRRYjZyVHRnMWNhTWRDSTNfVG9rZW46VVcyRmJNZ1NDbzhlWk94bmZmWmNSaVFKbnRnXzE3Njk3MTk0MDQ6MTc2OTcyMzAwNF9WNA)\\n\\n**假设：数据是正态分布。**\\n\\n取值范围：-1到1，0表示完全无相关性。⚠️注意：两个变量相关，不等于，一个变量的变化会导致另一个变量的变化。\\n\\n**分子是Covariance**\\n\\n如果假设被违反：用**spearman。**', '相关性只能说明两个变量在某种程度上有联系，但不能确定这种联系是否是因果关系。\\n\\n如何证明是因果性？\\n\\n**Difference-in-Differences, DID。**比较实验组和对照组在干预前后的变化，估计因果效应。']]\n"
          ]
        }
      ],
      "source": [
        "q_emb = embedder.get_embedding(\"什么是过拟合\")\n",
        "\n",
        "res = coll.query(\n",
        "    query_embeddings=[q_emb],  # 👈 明确告诉 Chroma 用哪个 embedding\n",
        "    n_results=3,\n",
        ")\n",
        "\n",
        "print(res[\"documents\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. State + Tools\n",
        "\n",
        "- **State**: `used_section_titles`, `round`, `session_start_time`, `interview_ended`\n",
        "- **Tools**: `get_current_time`, `pick_topic_from_rag`, `end_interview`; Coach is invoked via Team or a tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- State schema and tools (use run_context for state) ---\n",
        "from datetime import datetime\n",
        "from agno.run import RunContext\n",
        "from agno.tools import tool\n",
        "\n",
        "# Default session state for interview\n",
        "INTERVIEW_SESSION_STATE = {\n",
        "    \"used_section_titles\": [],\n",
        "    \"round\": 0,\n",
        "    \"session_start_time\": None,\n",
        "    \"interview_ended\": False,\n",
        "}\n",
        "\n",
        "@tool\n",
        "def get_current_time(run_context: RunContext) -> str:\n",
        "    \"\"\"Return current time. Use when starting a round or reporting duration.\"\"\"\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "@tool\n",
        "def pick_topic_from_rag(run_context: RunContext, query: str = \"data science interview topic\") -> str:\n",
        "    \"\"\"Retrieve one topic from the knowledge base that has NOT been used yet. Use this to pick the next question topic. Returns the section content; you should generate a question based on it.\"\"\"\n",
        "    used = run_context.session_state.get(\"used_section_titles\") or []\n",
        "    docs = knowledge.search(query=query, max_results=10)\n",
        "    for doc in docs:\n",
        "        title = doc.meta_data.get(\"section_title\") or doc.name\n",
        "        if title and title not in used:\n",
        "            run_context.session_state.setdefault(\"used_section_titles\", []).append(title)\n",
        "            return f\"[Section: {title}]\\n{doc.content}\"\n",
        "    return \"No unused topics left; you may wrap up the interview or repeat from a broader search.\"\n",
        "\n",
        "@tool\n",
        "def end_interview(run_context: RunContext) -> str:\n",
        "    \"\"\"Call when the candidate says they want to end or when you decide to finish. Marks interview as ended so summary can be generated.\"\"\"\n",
        "    run_context.session_state[\"interview_ended\"] = True\n",
        "    return \"Interview ended. Session summary will be generated.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Coach Agent (反馈/评分) + request_feedback tool\n",
        "\n",
        "Coach evaluates candidate answers using RAG-retrieved reference; Interviewer calls Coach via tool when feedback is requested."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Coach Agent: feedback/scoring; structured output ---\n",
        "import os\n",
        "from textwrap import dedent\n",
        "from dotenv import load_dotenv\n",
        "from agno.agent import Agent\n",
        "from agno.models.openrouter import OpenRouter\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "# Load environment variables from .env file if it exists\n",
        "load_dotenv()\n",
        "\n",
        "# Check if OPENROUTER_API_KEY is set\n",
        "if not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
        "    raise ValueError(\"Set OPENROUTER_API_KEY in your environment or .env file. Do not commit keys.\")\n",
        "\n",
        "class FeedbackOutput(BaseModel):\n",
        "    \"\"\"Structured feedback for one answer.\"\"\"\n",
        "    score_1_to_5: int = Field(..., ge=1, le=5, description=\"Score from 1 to 5\")\n",
        "    key_points_covered: List[str] = Field(..., description=\"Key points the candidate got right\")\n",
        "    missing_points: List[str] = Field(..., description=\"Important points missed (from reference)\")\n",
        "    suggestion: str = Field(..., description=\"One concise suggestion to improve\")\n",
        "\n",
        "coach_agent = Agent(\n",
        "    name=\"CoachAgent\",\n",
        "    model=OpenRouter(id=\"openai/gpt-4o-mini\", api_key=os.environ.get(\"OPENROUTER_API_KEY\")),\n",
        "    instructions=dedent(\"\"\"\n",
        "        You are an interview coach. Given the interview question, the candidate's answer, and the reference knowledge,\n",
        "        provide structured feedback: score (1-5), key points covered, missing points, and one suggestion.\n",
        "        Be fair and concise. Output in the required structured format.\n",
        "    \"\"\"),\n",
        "    output_schema=FeedbackOutput,\n",
        "    use_json_mode=True,\n",
        "    retries=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- request_feedback tool: calls Coach with RAG reference ---\n",
        "def make_request_feedback_tool(coach_agent, knowledge):\n",
        "    @tool\n",
        "    def request_feedback(run_context: RunContext, question: str, candidate_answer: str) -> str:\n",
        "        \"\"\"Ask the coach for feedback on the candidate's answer. Provide the question and the candidate's answer. Use after the candidate has answered a question.\"\"\"\n",
        "        ref_docs = knowledge.search(query=question, max_results=3)\n",
        "        reference = \"\\n\\n\".join(d.content for d in ref_docs) if ref_docs else \"No reference.\"\n",
        "        prompt = f\"Question: {question}\\n\\nCandidate answer: {candidate_answer}\\n\\nReference knowledge:\\n{reference}\\n\\nGive structured feedback (score, key points covered, missing points, suggestion).\"\n",
        "        out = coach_agent.run(prompt)\n",
        "        if hasattr(out.content, \"model_dump\"):\n",
        "            d = out.content.model_dump()\n",
        "            return f\"Score: {d.get('score_1_to_5')}/5 | Covered: {d.get('key_points_covered')} | Missing: {d.get('missing_points')} | Suggestion: {d.get('suggestion')}\"\n",
        "        return str(out.content)\n",
        "\n",
        "    return request_feedback\n",
        "\n",
        "request_feedback = make_request_feedback_tool(coach_agent, knowledge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Interviewer Agent + Team\n",
        "\n",
        "Interviewer: 出题/控场, tools + state + RAG. Coach: 反馈/评分. Team = Interviewer + Coach (interviewer can call coach via `request_feedback` tool)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Interviewer Agent: questions, control, tools, state, RAG ---\n",
        "import os\n",
        "from textwrap import dedent\n",
        "from dotenv import load_dotenv\n",
        "from agno.agent import Agent\n",
        "from agno.db.in_memory import InMemoryDb\n",
        "from agno.models.openrouter import OpenRouter\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "\n",
        "# Load environment variables from .env file if it exists\n",
        "load_dotenv()\n",
        "\n",
        "# Check if OPENROUTER_API_KEY is set\n",
        "if not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
        "    raise ValueError(\"Set OPENROUTER_API_KEY in your environment or .env file. Do not commit keys.\")\n",
        "\n",
        "INTERVIEW_TYPE = \"technical\"\n",
        "ROLE = \"Data Scientist\"\n",
        "SESSION_ID = \"interview_full_001\"\n",
        "DB = InMemoryDb()\n",
        "\n",
        "class InterviewTurn(BaseModel):\n",
        "    \"\"\"One interviewer turn: question + type + expected key points, OR session_summary when ending.\"\"\"\n",
        "    current_question: Optional[str] = Field(None, description=\"The interview question to ask the candidate\")\n",
        "    question_type: Optional[str] = Field(None, description=\"e.g. technical, behavioral\")\n",
        "    expected_key_points: Optional[List[str]] = Field(None, description=\"Key points to look for in a good answer\")\n",
        "    session_summary: Optional[str] = Field(None, description=\"If interview ended, summary of the session\")\n",
        "\n",
        "interviewer_agent = Agent(\n",
        "    name=\"InterviewAgent\",\n",
        "    model=OpenRouter(id=\"openai/gpt-4o-mini\", api_key=os.environ.get(\"OPENROUTER_API_KEY\")),\n",
        "    instructions=dedent(f\"\"\"\n",
        "        You are a professional interviewer for a mock data science interview.\n",
        "        Interview type: {INTERVIEW_TYPE}. Role: {ROLE}.\n",
        "        Use tools: get_current_time to track rounds; pick_topic_from_rag to get an unused topic and generate ONE question; request_feedback(question, candidate_answer) when the candidate has answered and you want to give feedback; end_interview when the candidate wants to stop or you finish.\n",
        "        Ask exactly ONE question per turn. Be concise. Output in the required structured format.\n",
        "        If the candidate says \"结束\" or \"end interview\", call end_interview and then output session_summary as a brief recap of the session.\n",
        "        \"\"\"),\n",
        "    tools=[get_current_time, pick_topic_from_rag, end_interview, request_feedback],\n",
        "    db=DB,\n",
        "    session_id=SESSION_ID,\n",
        "    session_state=INTERVIEW_SESSION_STATE,\n",
        "    add_session_state_to_context=True,\n",
        "    add_history_to_context=True,\n",
        "    knowledge=knowledge,\n",
        "    search_knowledge=True,\n",
        "    output_schema=InterviewTurn,\n",
        "    use_json_mode=True,\n",
        "    retries=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Team: Interviewer (lead) + Coach (called via request_feedback tool) ---\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from agno.team import Team\n",
        "from agno.models.openrouter import OpenRouter\n",
        "\n",
        "# Load environment variables from .env file if it exists\n",
        "load_dotenv()\n",
        "\n",
        "# Check if OPENROUTER_API_KEY is set\n",
        "if not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
        "    raise ValueError(\"Set OPENROUTER_API_KEY in your environment or .env file. Do not commit keys.\")\n",
        "\n",
        "interview_team = Team(\n",
        "    name=\"InterviewTeam\",\n",
        "    members=[interviewer_agent, coach_agent],\n",
        "    model=OpenRouter(id=\"openai/gpt-4o-mini\", api_key=os.environ.get(\"OPENROUTER_API_KEY\")),\n",
        ")\n",
        "\n",
        "# Note: Coach is invoked by the interviewer through the request_feedback tool, not by Team routing.\n",
        "# Team allows both agents to share the same run; the interviewer has the tools and leads the flow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Session Summary + Workflow\n",
        "\n",
        "- **Session Summary**: Triggered when interview ends; generate and display (or include in structured output).\n",
        "- **Workflow**: Set context → multi-round Q&A (run interviewer until end) → generate summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Session Summary: generate when interview_ended (run agent with summary prompt; history in context) ---\n",
        "def generate_session_summary(agent) -> str:\n",
        "    \"\"\"Generate session summary. Call after end_interview. Agent has conversation in context.\"\"\"\n",
        "    summary_prompt = \"The interview has ended. Based on our conversation, provide a brief session summary (3-5 sentences): topics covered, number of questions, and overall impression. Put the summary in session_summary if you use structured output, or reply with the summary text.\"\n",
        "    out = agent.run(summary_prompt)\n",
        "    if hasattr(out.content, \"session_summary\") and out.content.session_summary:\n",
        "        return out.content.session_summary\n",
        "    if hasattr(out.content, \"current_question\"):\n",
        "        return out.content.current_question  # model might put summary in this field\n",
        "    return str(out.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Workflow: run interview (set context → multi-round → summary)\n",
        "\n",
        "Single run example: one question + one answer + optional feedback. For full loop, run the next cell repeatedly or use the helper loop below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> documents                                                                                            \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[34mINFO\u001b[0m Found \u001b[1;36m10\u001b[0m documents                                                                                            \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Interview Turn ---\n",
            "current_question: Can you explain the concept of overfitting and how to handle it in machine learning? Please include techniques such as data augmentation and how validation might not completely solve the issue.\n",
            "question_type: technical\n",
            "expected_key_points: ['Definition of overfitting', 'Impact of overfitting on model performance', 'Data augmentation as a technique to handle overfitting', 'Regularization methods (e.g., L1, L2)', 'Use of validation and potential limitations']\n"
          ]
        }
      ],
      "source": [
        "# --- Workflow: one round (ask for first question) ---\n",
        "run = interviewer_agent.run(\"I'm ready. Please give me the first question (use pick_topic_from_rag to choose an unused topic).\")\n",
        "print(\"--- Interview Turn ---\")\n",
        "if hasattr(run.content, \"model_dump\"):\n",
        "    d = run.content.model_dump()\n",
        "    for k, v in d.items():\n",
        "        if v is not None:\n",
        "            print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(run.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> documents                                                                                             \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[34mINFO\u001b[0m Found \u001b[1;36m3\u001b[0m documents                                                                                             \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Response (may include feedback from Coach) ---\n",
            "{'current_question': 'Can you explain the concept of overfitting and how to handle it in machine learning? Please include techniques such as data augmentation and how validation might not completely solve the issue.', 'question_type': 'technical', 'expected_key_points': ['Definition of overfitting', 'Impact of overfitting on model performance', 'Data augmentation as a technique to handle overfitting', 'Regularization methods (e.g., L1, L2)', 'Use of validation and potential limitations'], 'session_summary': 'The candidate did not provide a complete answer about handling overfitting. While they correctly explained bias and variance, they failed to mention key techniques such as data augmentation, model selection, and validation limitations.'}\n"
          ]
        }
      ],
      "source": [
        "# --- Example: candidate answers, then request feedback (interviewer can call request_feedback tool) ---\n",
        "# Replace with the actual question from the previous run\n",
        "last_question = run.content.current_question if hasattr(run.content, \"current_question\") else \"Explain bias and variance.\"\n",
        "candidate_answer = \"Bias is the difference between model prediction and true value; high bias means underfitting. Variance is sensitivity to data; high variance means overfitting. They trade off.\"\n",
        "run2 = interviewer_agent.run(f\"I'll answer: {candidate_answer}. Please give me feedback on my answer.\")\n",
        "print(\"--- Response (may include feedback from Coach) ---\")\n",
        "print(run2.content if not hasattr(run2.content, \"model_dump\") else run2.content.model_dump())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- End turn ---\n",
            "{'current_question': None, 'question_type': None, 'expected_key_points': None, 'session_summary': 'The candidate answered a question about overfitting but did not cover key points around handling overfitting, such as data augmentation and validation limitations. They explained bias and variance but lacked detail on practical techniques.'}\n",
            "\n",
            "--- Session Summary ---\n",
            "The interview covered one question related to the concept of overfitting in machine learning. The candidate briefly discussed bias and variance but did not fully address how to handle overfitting or the limitations of validation. Overall, the response indicated a basic understanding of the concepts, but more detailed knowledge of practical techniques was necessary for a stronger performance.\n"
          ]
        }
      ],
      "source": [
        "# --- End interview and get Session Summary ---\n",
        "run_end = interviewer_agent.run(\"I want to end the interview. Please wrap up.\")\n",
        "print(\"--- End turn ---\")\n",
        "print(run_end.content.model_dump() if hasattr(run_end.content, \"model_dump\") else run_end.content)\n",
        "\n",
        "# Generate and display session summary\n",
        "summary = generate_session_summary(interviewer_agent)\n",
        "print(\"\\n--- Session Summary ---\")\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Optional: Workflow loop (set context → multi-round until \"结束\" → summary) ---\n",
        "def run_interview_workflow(agent, max_rounds: int = 5):\n",
        "    \"\"\"Run interview: multi-round until user says end or max_rounds. Then print summary.\"\"\"\n",
        "    print(\"Interview started. Say '结束' or 'end' to finish.\\n\")\n",
        "    for r in range(max_rounds):\n",
        "        user_input = input(f\"Round {r+1} (you): \").strip()\n",
        "        if not user_input:\n",
        "            continue\n",
        "        if user_input.lower() in (\"结束\", \"end\", \"结束面试\"):\n",
        "            _ = agent.run(\"I want to end the interview. Please wrap up.\")\n",
        "            break\n",
        "        out = agent.run(user_input)\n",
        "        print(\"Agent:\", getattr(out.content, \"current_question\", out.content))\n",
        "    print(\"\\n--- Session Summary ---\")\n",
        "    print(generate_session_summary(agent))\n",
        "\n",
        "# Uncomment to run interactive loop:\n",
        "# run_interview_workflow(interviewer_agent, max_rounds=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwdQU9rZ1rg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (agno_env)",
      "language": "python",
      "name": "agno_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
