{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AgnoAgent Notebook — Overview & Run Guide\n",
        "\n",
        "## 1. Structure (top to bottom)\n",
        "\n",
        "| Block | Purpose |\n",
        "|-------|---------|\n",
        "| **0. Install** | Install agno, openai, google-genai, mcp, fastapi, sqlalchemy |\n",
        "| **1. Basic Agent** | OpenRouter + InMemoryDb chat agent; run \"Hello\" |\n",
        "| **2. Agent + Tools + Structured Output** | `add` tool; Response schema (chat / answer / tools_used) |\n",
        "| **3. Interview Agent (simple)** | Single agent: technical + Data Scientist context; one question per turn; InterviewTurn (question, type, expected key points) |\n",
        "| **4. Full Interview System** | RAG knowledge base, State, tools, Coach Agent, Team, Session Summary, Workflow |\n",
        "\n",
        "## 2. What each block does\n",
        "\n",
        "### Block 1: Install\n",
        "- Install `agno`, `openai`, `google-genai`, `mcp`, `fastapi`, `sqlalchemy`. Run once.\n",
        "\n",
        "### Block 2: Basic Agent (OpenRouter + memory)\n",
        "- **OpenRouter** `gpt-4o-mini`, **InMemoryDb** for history. `BasicAgent` replies as \"You are a helpful AI Assistant\". Run `agent.run(\"Hello, how are you?\")` for a reply.\n",
        "\n",
        "### Block 3: Agent + Tools + Structured Output\n",
        "- **Tool**: `add(a, b)`. **Structured output**: Pydantic `Response` with `chat`, `answer`, `tools_used`. Ask \"What's 10 + 2?\" to trigger `add` and structured reply.\n",
        "\n",
        "### Block 4: Interview Agent (Phase 1, single agent)\n",
        "- **Context**: technical interview, Data Scientist role (in instructions). **Output**: `InterviewTurn` (question, type, expected key points). No RAG/State/Team. Run `interview_agent.run(\"I'm ready. Please give me the first question.\")`.\n",
        "\n",
        "### Block 5: Full system — RAG knowledge base\n",
        "- Chunk **ds notes.markdown** by `##` into sections. Build **ChromaDb** vector store, **Knowledge** for topic-based questions. Set `DS_NOTES_PATH` to your local path.\n",
        "\n",
        "### Block 6: State + Tools\n",
        "- **State**: `used_section_titles`, `round`, `session_start_time`, `interview_ended`. **Tools**: `get_current_time`, `pick_topic_from_rag` (pick unused topic for next question), `end_interview`. Used by Interviewer Agent.\n",
        "\n",
        "### Block 7: Coach Agent + request_feedback\n",
        "- **Coach**: feedback/scoring from question + candidate answer + RAG reference (score, covered/missing points, suggestion). **request_feedback** tool: Interviewer calls it after an answer; it queries RAG, calls Coach, returns formatted feedback.\n",
        "\n",
        "### Block 8: Interviewer Agent + Team\n",
        "- **Interviewer**: asks questions, runs flow; uses all tools + State + RAG; outputs `InterviewTurn` (or `session_summary` when ending). **Team**: Interviewer + Coach; Coach is invoked via `request_feedback`, not Team routing.\n",
        "\n",
        "### Block 9: Session Summary + Workflow\n",
        "- **Session Summary**: when user says \"end\", run `generate_session_summary(agent)` to produce a short recap from conversation history. **Workflow**: set context → multi-round Q&A → user says end → `end_interview` → Session Summary.\n",
        "\n",
        "### Block 10: How to run\n",
        "- **Single-run demo**: run \"ask first question\" → \"candidate answer + request feedback\" → \"end interview + Session Summary\".\n",
        "- **Interactive**: uncomment `run_interview_workflow(interviewer_agent, max_rounds=5)`, type answers in terminal; say \"end\" to finish and print summary.\n",
        "\n",
        "## 3. Run order\n",
        "\n",
        "1. **Environment**: Python, recommended env (e.g. `agno_env`). **API Key**: `OPENROUTER_API_KEY` in env or fallback in code.\n",
        "2. Run **Install**, then **Basic Agent** and **Agent + Tools**.\n",
        "3. For **full interview**: have `ds notes.markdown`, set `DS_NOTES_PATH`, then run RAG, State+Tools, Coach, Interviewer, Team, Summary, Workflow in order.\n",
        "4. For **simple interview** only: run up to Block 4; no RAG/ChromaDb.\n",
        "5. **Interactive**: after full setup, run `run_interview_workflow(...)`, say \"end\" to end.\n",
        "\n",
        "## 4. Dependencies & paths\n",
        "\n",
        "- **ChromaDb**: required for full system; run `!pip install chromadb` if needed.\n",
        "- **OPENROUTER_API_KEY**: must be valid.\n",
        "- **DS_NOTES_PATH**: path to your `ds notes.markdown` for RAG."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtmdi_IgUnIH",
        "outputId": "216fd78b-e59e-4e59-f71d-c8af9e1f4f2f"
      },
      "source": [
        "!pip install agno openai google-genai mcp fastapi sqlalchemy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI0ZQ78LUytH"
      },
      "source": [
        "# Build Agno Agent with OpenRouter\n",
        "\n",
        "Build a basic agent, then expand the agent with other Agno modules\n",
        "\n",
        "Ask me for an OpenRouter API key\n",
        "\n",
        "- [Agno Docs: Building Agents](https://docs.agno.com/basics/agents/building-agents)\n",
        "- [Agno Docs: OpenRouter](https://docs.agno.com/integrations/models/gateways/openrouter/overview)\n",
        "- [Cookbook/Examples](https://github.com/agno-agi/agno/tree/main/cookbook)\n",
        "\n",
        "Set `OPENROUTER_API_KEY` in your environment, or in the code cells below.\n",
        "\n",
        "### Models\n",
        "[See all OpenRouter models](https://openrouter.ai/models)\n",
        "- Search by price, category, parameters allowed, etc\n",
        "- **Price**: Use Free models as able, but you might need some of the paid ones for more complex tasks.\n",
        "    - Try to use ones that cost less than $1.00 per 1M / output tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pBh1c7yU1VX"
      },
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "from agno.agent import Agent\n",
        "from agno.models.openrouter import OpenRouter\n",
        "from agno.db.in_memory import InMemoryDb\n",
        "\n",
        "# For local run: use env var OPENROUTER_API_KEY if set, otherwise use key below\n",
        "if 'OPENROUTER_API_KEY' not in os.environ:\n",
        "    os.environ['OPENROUTER_API_KEY'] = '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'\n",
        "DB = InMemoryDb()\n",
        "SESSION_ID = 'session001'\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"BasicAgent\",\n",
        "    model=OpenRouter(\n",
        "        id='openai/gpt-4o-mini',\n",
        "        api_key=os.environ['OPENROUTER_API_KEY'],\n",
        "    ),\n",
        "    instructions=dedent(\n",
        "        \"\"\"\n",
        "        You are a helpful AI Assistant\n",
        "        \"\"\"\n",
        "    ),\n",
        "    db=DB,\n",
        "    session_id=SESSION_ID,\n",
        "    add_history_to_context=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K74XZIhVHXJ",
        "outputId": "01888e93-1c5a-4124-becf-cb6df9efa004"
      },
      "source": [
        "response = agent.run(\"Hello, how are you?\")\n",
        "print(response.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTZO3ow2Xesa"
      },
      "source": [
        "## Tasks\n",
        "Review all the modules of Agno SDK and build an over-engineered Agent that demonstrates key concepts and features\n",
        "\n",
        "1. [Agno Context Engineering](https://docs.agno.com/context/engineering/overview)\n",
        "\n",
        "2. [Structured Outputs with Pydantic](https://docs.agno.com/basics/input-output/overview#structured-output)\n",
        "\n",
        "2. [State Management / Agentic State](https://docs.agno.com/context/state/overview)\n",
        "\n",
        "3. [Knowledge / Agentic RAG](https://docs.agno.com/context/knowledge/overview)\n",
        "\n",
        "4. [Session Summary Agent](https://docs.agno.com/context/knowledge/overview)\n",
        "\n",
        "5. [Tools and Toolkits](https://docs.agno.com/integrations/toolkits/overview)\n",
        "\n",
        "6. [Reasoning](https://docs.agno.com/features/reasoning/overview)\n",
        "\n",
        "7. [Build a second agent and use as a `Team`](https://docs.agno.com/basics/teams/overview)\n",
        "\n",
        "8. [Build `Steps` and use in a `Workflow`](https://docs.agno.com/basics/workflows/building-workflows)\n",
        "\n",
        "> Does not need to especially sophisticated, and does not need to be an especially useful agent, just work to get the different elements integrated\n",
        "\n",
        "For example, add a basic tool and structured outputs to your agent:\n",
        "\n",
        "### Agent with Tool and Structured Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlEg3o6SXHHf",
        "outputId": "7189560e-1cc1-411a-88d4-2997ac040827"
      },
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "from agno.agent import Agent\n",
        "from agno.models.openrouter import OpenRouter\n",
        "from agno.db.in_memory import InMemoryDb\n",
        "from agno.tools import tool\n",
        "from pydantic import BaseModel, Field\n",
        "from typing_extensions import Optional, List\n",
        "\n",
        "if 'OPENROUTER_API_KEY' not in os.environ:\n",
        "    os.environ['OPENROUTER_API_KEY'] = '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'\n",
        "DB = InMemoryDb()\n",
        "SESSION_ID = 'session001'\n",
        "\n",
        "# Create simple arithmetic tool\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\" A tool that adds integers together \"\"\"\n",
        "    return a + b\n",
        "\n",
        "# Create structured output schema with Typed data\n",
        "class Response(BaseModel):\n",
        "    \"\"\"\n",
        "    A response to a user input that includes:\n",
        "    - a normal LLM chat response\n",
        "    - a numerical answer if the user input required math tools\n",
        "    - a list of tools used (names of tools)\n",
        "    \"\"\"\n",
        "    chat: str = Field(..., description=\"The chat response to the user input\")\n",
        "    answer: Optional[int] = Field(\n",
        "        None,\n",
        "        description=\"Numerical answer to the user input if it required math tools\"\n",
        "    )\n",
        "    tools_used: List[str]\n",
        "\n",
        "# Create agent\n",
        "agent = Agent(\n",
        "    name=\"BasicAgent\",\n",
        "    model=OpenRouter(\n",
        "        id='openai/gpt-4o-mini',\n",
        "        api_key=os.environ['OPENROUTER_API_KEY'],\n",
        "    ),\n",
        "    instructions=dedent(\n",
        "        \"\"\"\n",
        "        You are a helpful AI Assistant. You can add two numbers together\n",
        "        using a tool, which is more accurate than LLM native arithmetic.\n",
        "        \"\"\"\n",
        "    ),\n",
        "    tools=[add],\n",
        "    db=DB,\n",
        "    session_id=SESSION_ID,\n",
        "    add_history_to_context=True,\n",
        "    output_schema=Response,\n",
        "    use_json_mode=True,  # Helps with some endpoint/model compatibility issues\n",
        "    retries=3\n",
        ")\n",
        "\n",
        "# We'll skip the pretty print response and get the data as a dict/json\n",
        "run = agent.run(\"Hey! What's 10 + 2?\")  # to display output\n",
        "print(run.content.model_dump())\n",
        "\n",
        "# Now we can access response items programatically, enabling all sorts of follow on operations\n",
        "print(\"\\nAccess individual fields from response:\")\n",
        "print(f\"{type(run.content.chat)}: {run.content.chat}\")\n",
        "print(f\"{type(run.content.answer)}: {run.content.answer}\")\n",
        "print(f\"{type(run.content.tools_used)}: {run.content.tools_used}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interview Agent (Phase 1: Single Agent + Structured Output + Context)\n",
        "\n",
        "Mock interview coach: one agent asks questions based on **context** (interview type, role) and returns **structured output** (current question + type + expected key points). No RAG/State/Team yet—just get the conversation working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "from agno.agent import Agent\n",
        "from agno.models.openrouter import OpenRouter\n",
        "from agno.db.in_memory import InMemoryDb\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "# API key: set OPENROUTER_API_KEY in env, or use fallback below for local run\n",
        "if \"OPENROUTER_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = \"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\"\n",
        "\n",
        "DB = InMemoryDb()\n",
        "SESSION_ID = \"interview_session_001\"\n",
        "\n",
        "# --- Context (simple context engineering) ---\n",
        "INTERVIEW_TYPE = \"technical\"\n",
        "ROLE = \"Data Scientist\"\n",
        "\n",
        "# --- Structured output: one interview turn = question + type + expected key points ---\n",
        "class InterviewTurn(BaseModel):\n",
        "    \"\"\"One interviewer turn: the question to ask and what to look for in the answer.\"\"\"\n",
        "    current_question: str = Field(..., description=\"The interview question to ask the candidate\")\n",
        "    question_type: str = Field(..., description=\"e.g. technical, behavioral, system_design\")\n",
        "    expected_key_points: List[str] = Field(..., description=\"Key points or themes to look for in a good answer\")\n",
        "\n",
        "# --- Interview Agent: single agent, structured output, context in instructions ---\n",
        "interview_agent = Agent(\n",
        "    name=\"InterviewAgent\",\n",
        "    model=OpenRouter(\n",
        "        id=\"openai/gpt-4o-mini\",\n",
        "        api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
        "    ),\n",
        "    instructions=dedent(f\"\"\"\n",
        "        You are a professional interviewer conducting a mock data science interview.\n",
        "        Interview type: {INTERVIEW_TYPE}.\n",
        "        Role: {ROLE}.\n",
        "        Focus on data science topics: statistics, ML, Python/pandas, SQL, A/B testing, metrics, etc.\n",
        "        Ask exactly ONE question per turn. Be concise and professional.\n",
        "        Output your question and the expected key points in the required structured format.\n",
        "        \"\"\"),\n",
        "    db=DB,\n",
        "    session_id=SESSION_ID,\n",
        "    add_history_to_context=True,\n",
        "    output_schema=InterviewTurn,\n",
        "    use_json_mode=True,\n",
        "    retries=3,\n",
        ")\n",
        "\n",
        "# --- Run: ask for the first question ---\n",
        "run = interview_agent.run(\"I'm ready. Please give me the first question.\")\n",
        "print(\"Raw output (dict):\", run.content.model_dump())\n",
        "print(\"\\n--- Formatted ---\")\n",
        "print(f\"Question: {run.content.current_question}\")\n",
        "print(f\"Type: {run.content.question_type}\")\n",
        "print(f\"Expected key points: {run.content.expected_key_points}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Interview Agent (Full): State + RAG + Tools + Team + Session Summary + Workflow\n",
        "\n",
        "- **State**: Track `used_section_titles`, `round`, `session_start_time`, `interview_ended`\n",
        "- **RAG**: DS notes markdown chunked by `##`, used for question generation and feedback reference\n",
        "- **Tools**: `get_current_time`, `pick_topic_from_rag`, `end_interview`, `request_feedback` (calls Coach)\n",
        "- **Team**: Interviewer (questions / flow) + Coach (feedback / scoring)\n",
        "- **Session Summary**: Triggered on \"end interview\", included in structured output or displayed separately\n",
        "- **Workflow**: Set context → multi-round Q&A (team) → summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install chromadb for vector store (run if ModuleNotFoundError: chromadb)\n",
        "!pip install chromadb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 1. RAG: Build knowledge base from DS notes (chunk by ## sections) ---\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "if \"OPENROUTER_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = \"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\"  # set your key\n",
        "# ChromaDb default embedder may need OPENAI_API_KEY; or pass a custom embedder to ChromaDb\n",
        "DS_NOTES_PATH = \"/Users/joy/Desktop/ds notes.markdown\"\n",
        "\n",
        "def parse_markdown_by_h2(path: str) -> list[tuple[str, str]]:\n",
        "    \"\"\"Parse markdown file into (section_title, content) pairs by ## headers.\"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "    # Split by ## but keep the header line with the content\n",
        "    pattern = re.compile(r\"^##\\s+(.+)$\", re.MULTILINE)\n",
        "    parts = pattern.split(text)\n",
        "    # parts[0] is content before first ##; then [title1, content1, title2, content2, ...]\n",
        "    sections = []\n",
        "    if len(parts) <= 1:\n",
        "        if text.strip():\n",
        "            sections.append((\"general\", text))\n",
        "        return sections\n",
        "    # Skip leading content without ## (e.g. first line or intro)\n",
        "    i = 1\n",
        "    while i + 1 < len(parts):\n",
        "        title, content = parts[i].strip(), (parts[i + 1] or \"\").strip()\n",
        "        if title or content:\n",
        "            sections.append((title or \"section\", content or \"(no content)\"))\n",
        "        i += 2\n",
        "    return sections\n",
        "\n",
        "sections = parse_markdown_by_h2(DS_NOTES_PATH)\n",
        "print(f\"Parsed {len(sections)} sections (##). First 3 titles: {[t for t, _ in sections[:3]]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from agno.knowledge import Knowledge\n",
        "from agno.knowledge.embedder.openai import OpenAIEmbedder\n",
        "from agno.vectordb.chroma import ChromaDb\n",
        "from chromadb import PersistentClient\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "CHROMA_PATH = \"./tmp_interview_chroma\"\n",
        "COLLECTION = \"ds_notes_emb1536\"\n",
        "\n",
        "Path(CHROMA_PATH).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "EMBED_MODEL = \"text-embedding-3-small\"  # 1536 dim\n",
        "embedder = OpenAIEmbedder(\n",
        "    id=EMBED_MODEL,\n",
        "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        ")\n",
        "\n",
        "# 1. Remove existing collection if present\n",
        "client = PersistentClient(path=CHROMA_PATH)\n",
        "if COLLECTION in [c.name for c in client.list_collections()]:\n",
        "    client.delete_collection(COLLECTION)\n",
        "\n",
        "# 2. Create new collection (embedding dim fixed here)\n",
        "coll = client.get_or_create_collection(\n",
        "    COLLECTION,\n",
        "    metadata={\"hnsw:space\": \"cosine\"},\n",
        ")\n",
        "\n",
        "# 3. Upsert sections\n",
        "inserted = skipped = failed = 0\n",
        "for i, (title, content) in enumerate(sections):\n",
        "    if not isinstance(content, str):\n",
        "        skipped += 1\n",
        "        continue\n",
        "    if len(content.strip()) < 30 or content.strip().startswith(\"![\"):\n",
        "        skipped += 1\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        emb = embedder.get_embedding(content)\n",
        "        if not emb:\n",
        "            failed += 1\n",
        "            continue\n",
        "\n",
        "        coll.upsert(\n",
        "            ids=[f\"ds_sec_{i}\"],\n",
        "            embeddings=[emb],\n",
        "            documents=[content],\n",
        "            metadatas=[{\"section_title\": title}],\n",
        "        )\n",
        "        inserted += 1\n",
        "    except Exception as e:\n",
        "        failed += 1\n",
        "        print(\"Insert fail:\", e)\n",
        "\n",
        "print(f\"Inserted={inserted}, skipped={skipped}, failed={failed}\")\n",
        "\n",
        "# 4. Wire Knowledge / ChromaDb to this collection\n",
        "vector_db = ChromaDb(\n",
        "    collection=COLLECTION,\n",
        "    path=CHROMA_PATH,\n",
        "    embedder=embedder,\n",
        "    persistent_client=True,\n",
        ")\n",
        "\n",
        "knowledge = Knowledge(\n",
        "    name=COLLECTION,\n",
        "    vector_db=vector_db,\n",
        "    max_results=5,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "q_emb = embedder.get_embedding(\"what is overfitting\")\n",
        "\n",
        "res = coll.query(\n",
        "    query_embeddings=[q_emb],  # use this embedding for Chroma query\n",
        "    n_results=3,\n",
        ")\n",
        "\n",
        "print(res[\"documents\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. State + Tools\n",
        "\n",
        "- **State**: `used_section_titles`, `round`, `session_start_time`, `interview_ended`\n",
        "- **Tools**: `get_current_time`, `pick_topic_from_rag`, `end_interview`; Coach is invoked via Team or a tool."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- State schema and tools (use run_context for state) ---\n",
        "from datetime import datetime\n",
        "from agno.run import RunContext\n",
        "from agno.tools import tool\n",
        "\n",
        "# Default session state for interview\n",
        "INTERVIEW_SESSION_STATE = {\n",
        "    \"used_section_titles\": [],\n",
        "    \"round\": 0,\n",
        "    \"session_start_time\": None,\n",
        "    \"interview_ended\": False,\n",
        "}\n",
        "\n",
        "@tool\n",
        "def get_current_time(run_context: RunContext) -> str:\n",
        "    \"\"\"Return current time. Use when starting a round or reporting duration.\"\"\"\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "@tool\n",
        "def pick_topic_from_rag(run_context: RunContext, query: str = \"data science interview topic\") -> str:\n",
        "    \"\"\"Retrieve one topic from the knowledge base that has NOT been used yet. Use this to pick the next question topic. Returns the section content; you should generate a question based on it.\"\"\"\n",
        "    used = run_context.session_state.get(\"used_section_titles\") or []\n",
        "    docs = knowledge.search(query=query, max_results=10)\n",
        "    for doc in docs:\n",
        "        title = doc.meta_data.get(\"section_title\") or doc.name\n",
        "        if title and title not in used:\n",
        "            run_context.session_state.setdefault(\"used_section_titles\", []).append(title)\n",
        "            return f\"[Section: {title}]\\n{doc.content}\"\n",
        "    return \"No unused topics left; you may wrap up the interview or repeat from a broader search.\"\n",
        "\n",
        "@tool\n",
        "def end_interview(run_context: RunContext) -> str:\n",
        "    \"\"\"Call when the candidate says they want to end or when you decide to finish. Marks interview as ended so summary can be generated.\"\"\"\n",
        "    run_context.session_state[\"interview_ended\"] = True\n",
        "    return \"Interview ended. Session summary will be generated.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Coach Agent (feedback/scoring) + request_feedback tool\n",
        "\n",
        "Coach evaluates candidate answers using RAG-retrieved reference; Interviewer calls Coach via tool when feedback is requested."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Coach Agent: feedback/scoring; structured output ---\n",
        "from textwrap import dedent\n",
        "from agno.agent import Agent\n",
        "from agno.models.openrouter import OpenRouter\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "class FeedbackOutput(BaseModel):\n",
        "    \"\"\"Structured feedback for one answer.\"\"\"\n",
        "    score_1_to_5: int = Field(..., ge=1, le=5, description=\"Score from 1 to 5\")\n",
        "    key_points_covered: List[str] = Field(..., description=\"Key points the candidate got right\")\n",
        "    missing_points: List[str] = Field(..., description=\"Important points missed (from reference)\")\n",
        "    suggestion: str = Field(..., description=\"One concise suggestion to improve\")\n",
        "\n",
        "coach_agent = Agent(\n",
        "    name=\"CoachAgent\",\n",
        "    model=OpenRouter(id=\"openai/gpt-4o-mini\", api_key=os.environ.get(\"OPENROUTER_API_KEY\")),\n",
        "    instructions=dedent(\"\"\"\n",
        "        You are an interview coach. Given the interview question, the candidate's answer, and the reference knowledge,\n",
        "        provide structured feedback: score (1-5), key points covered, missing points, and one suggestion.\n",
        "        Be fair and concise. Output in the required structured format.\n",
        "    \"\"\"),\n",
        "    output_schema=FeedbackOutput,\n",
        "    use_json_mode=True,\n",
        "    retries=2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- request_feedback tool: calls Coach with RAG reference ---\n",
        "def make_request_feedback_tool(coach_agent, knowledge):\n",
        "    @tool\n",
        "    def request_feedback(run_context: RunContext, question: str, candidate_answer: str) -> str:\n",
        "        \"\"\"Ask the coach for feedback on the candidate's answer. Provide the question and the candidate's answer. Use after the candidate has answered a question.\"\"\"\n",
        "        ref_docs = knowledge.search(query=question, max_results=3)\n",
        "        reference = \"\\n\\n\".join(d.content for d in ref_docs) if ref_docs else \"No reference.\"\n",
        "        prompt = f\"Question: {question}\\n\\nCandidate answer: {candidate_answer}\\n\\nReference knowledge:\\n{reference}\\n\\nGive structured feedback (score, key points covered, missing points, suggestion).\"\n",
        "        out = coach_agent.run(prompt)\n",
        "        if hasattr(out.content, \"model_dump\"):\n",
        "            d = out.content.model_dump()\n",
        "            return f\"Score: {d.get('score_1_to_5')}/5 | Covered: {d.get('key_points_covered')} | Missing: {d.get('missing_points')} | Suggestion: {d.get('suggestion')}\"\n",
        "        return str(out.content)\n",
        "\n",
        "    return request_feedback\n",
        "\n",
        "request_feedback = make_request_feedback_tool(coach_agent, knowledge)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Interviewer Agent + Team\n",
        "\n",
        "Interviewer: questions / flow, tools + state + RAG. Coach: feedback / scoring. Team = Interviewer + Coach (interviewer calls coach via `request_feedback` tool)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Interviewer Agent: questions, control, tools, state, RAG ---\n",
        "from textwrap import dedent\n",
        "from agno.agent import Agent\n",
        "from agno.db.in_memory import InMemoryDb\n",
        "from agno.models.openrouter import OpenRouter\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "\n",
        "INTERVIEW_TYPE = \"technical\"\n",
        "ROLE = \"Data Scientist\"\n",
        "SESSION_ID = \"interview_full_001\"\n",
        "DB = InMemoryDb()\n",
        "\n",
        "class InterviewTurn(BaseModel):\n",
        "    \"\"\"One interviewer turn: question + type + expected key points, OR session_summary when ending.\"\"\"\n",
        "    current_question: Optional[str] = Field(None, description=\"The interview question to ask the candidate\")\n",
        "    question_type: Optional[str] = Field(None, description=\"e.g. technical, behavioral\")\n",
        "    expected_key_points: Optional[List[str]] = Field(None, description=\"Key points to look for in a good answer\")\n",
        "    session_summary: Optional[str] = Field(None, description=\"If interview ended, summary of the session\")\n",
        "\n",
        "interviewer_agent = Agent(\n",
        "    name=\"InterviewAgent\",\n",
        "    model=OpenRouter(id=\"openai/gpt-4o-mini\", api_key=os.environ.get(\"OPENROUTER_API_KEY\")),\n",
        "    instructions=dedent(f\"\"\"\n",
        "        You are a professional interviewer for a mock data science interview.\n",
        "        Interview type: {INTERVIEW_TYPE}. Role: {ROLE}.\n",
        "        Use tools: get_current_time to track rounds; pick_topic_from_rag to get an unused topic and generate ONE question; request_feedback(question, candidate_answer) when the candidate has answered and you want to give feedback; end_interview when the candidate wants to stop or you finish.\n",
        "        Ask exactly ONE question per turn. Be concise. Output in the required structured format.\n",
        "        If the candidate says \"end\" or \"end interview\", call end_interview and then output session_summary as a brief recap of the session.\n",
        "        \"\"\"),\n",
        "    tools=[get_current_time, pick_topic_from_rag, end_interview, request_feedback],\n",
        "    db=DB,\n",
        "    session_id=SESSION_ID,\n",
        "    session_state=INTERVIEW_SESSION_STATE,\n",
        "    add_session_state_to_context=True,\n",
        "    add_history_to_context=True,\n",
        "    knowledge=knowledge,\n",
        "    search_knowledge=True,\n",
        "    output_schema=InterviewTurn,\n",
        "    use_json_mode=True,\n",
        "    retries=3,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Team: Interviewer (lead) + Coach (called via request_feedback tool) ---\n",
        "from agno.team import Team\n",
        "\n",
        "interview_team = Team(\n",
        "    name=\"InterviewTeam\",\n",
        "    members=[interviewer_agent, coach_agent],\n",
        "    model=OpenRouter(id=\"openai/gpt-4o-mini\", api_key=os.environ.get(\"OPENROUTER_API_KEY\")),\n",
        ")\n",
        "\n",
        "# Note: Coach is invoked by the interviewer through the request_feedback tool, not by Team routing.\n",
        "# Team allows both agents to share the same run; the interviewer has the tools and leads the flow."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Session Summary + Workflow\n",
        "\n",
        "- **Session Summary**: Triggered when interview ends; generate and display (or include in structured output).\n",
        "- **Workflow**: Set context → multi-round Q&A (run interviewer until end) → generate summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Session Summary: generate when interview_ended (run agent with summary prompt; history in context) ---\n",
        "def generate_session_summary(agent) -> str:\n",
        "    \"\"\"Generate session summary. Call after end_interview. Agent has conversation in context.\"\"\"\n",
        "    summary_prompt = \"The interview has ended. Based on our conversation, provide a brief session summary (3-5 sentences): topics covered, number of questions, and overall impression. Put the summary in session_summary if you use structured output, or reply with the summary text.\"\n",
        "    out = agent.run(summary_prompt)\n",
        "    if hasattr(out.content, \"session_summary\") and out.content.session_summary:\n",
        "        return out.content.session_summary\n",
        "    if hasattr(out.content, \"current_question\"):\n",
        "        return out.content.current_question  # model might put summary in this field\n",
        "    return str(out.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Workflow: run interview (set context → multi-round → summary)\n",
        "\n",
        "Single run example: one question + one answer + optional feedback. For full loop, run the next cell repeatedly or use the helper loop below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Workflow: one round (ask for first question) ---\n",
        "run = interviewer_agent.run(\"I'm ready. Please give me the first question (use pick_topic_from_rag to choose an unused topic).\")\n",
        "print(\"--- Interview Turn ---\")\n",
        "if hasattr(run.content, \"model_dump\"):\n",
        "    d = run.content.model_dump()\n",
        "    for k, v in d.items():\n",
        "        if v is not None:\n",
        "            print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(run.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Example: candidate answers, then request feedback (interviewer can call request_feedback tool) ---\n",
        "# Replace with the actual question from the previous run\n",
        "last_question = run.content.current_question if hasattr(run.content, \"current_question\") else \"Explain bias and variance.\"\n",
        "candidate_answer = \"Bias is the difference between model prediction and true value; high bias means underfitting. Variance is sensitivity to data; high variance means overfitting. They trade off.\"\n",
        "run2 = interviewer_agent.run(f\"I'll answer: {candidate_answer}. Please give me feedback on my answer.\")\n",
        "print(\"--- Response (may include feedback from Coach) ---\")\n",
        "print(run2.content if not hasattr(run2.content, \"model_dump\") else run2.content.model_dump())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- End interview and get Session Summary ---\n",
        "run_end = interviewer_agent.run(\"I want to end the interview. Please wrap up.\")\n",
        "print(\"--- End turn ---\")\n",
        "print(run_end.content.model_dump() if hasattr(run_end.content, \"model_dump\") else run_end.content)\n",
        "\n",
        "# Generate and display session summary\n",
        "summary = generate_session_summary(interviewer_agent)\n",
        "print(\"\\n--- Session Summary ---\")\n",
        "print(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Workflow loop: multi-round until \"end\" → summary ---\n",
        "def run_interview_workflow(agent, max_rounds: int = 5):\n",
        "    \"\"\"Run interview: multi-round until user says end or max_rounds. Then print summary.\"\"\"\n",
        "    print(\"Interview started. Say 'end' or 'end interview' to finish.\\n\")\n",
        "    for r in range(max_rounds):\n",
        "        user_input = input(f\"Round {r+1} (you): \").strip()\n",
        "        if not user_input:\n",
        "            continue\n",
        "        if user_input.lower() in (\"end\", \"end interview\"):\n",
        "            _ = agent.run(\"I want to end the interview. Please wrap up.\")\n",
        "            break\n",
        "        out = agent.run(user_input)\n",
        "        print(\"Agent:\", getattr(out.content, \"current_question\", out.content))\n",
        "    print(\"\\n--- Session Summary ---\")\n",
        "    print(generate_session_summary(agent))\n",
        "\n",
        "# Uncomment to run interactive loop:\n",
        "# run_interview_workflow(interviewer_agent, max_rounds=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERwdQU9rZ1rg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (agno_env)",
      "language": "python",
      "name": "agno_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}